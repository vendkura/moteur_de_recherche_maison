Pour finir on va implementer un tokenizer plus complexe que un simple d ́ecoupage
de mots. Pour cela on va utiliser la fonction word tokenize() de la biblioth`eque NLTK:
import nltk
tokens = nltk. word tokenize (content , language=’french’)
. . . `a vous de le placer dans le bon endroit et comparer la qualit ́e des r ́esultats
obtenus.